{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "paperback-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-access",
   "metadata": {},
   "source": [
    "#### Programming Note:\n",
    "- I prefer to encapsulate everything within a function rather than have variables within just the notebook.\n",
    "- While I understand that this takes away from some of the perks of the sandbox environment of Jupyter Notebooks, I feel that maintaining the scope of data/variables in this way prevents issues further down the road, such as\n",
    "    - conflicting variables/variable names,\n",
    "    - unintended changes,\n",
    "    - functions confusing which data to use\n",
    "    - mutability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-confirmation",
   "metadata": {},
   "source": [
    "#### Data Note\n",
    "- I have chosen to undo some of the cleaning I perform in my webscraping package in order to demonstrate some common cleaning examples\n",
    "- By doing this, I can simulate likely requirements when dealing with unfamiliar/third-party data sources, such as eliminating null values and cleaning up columns/rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "assigned-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_data_path() -> str:\n",
    "    return '/'.join([\n",
    "        os.getcwd().replace('src', 'data'),\n",
    "        'season-data-raw.csv'\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "painful-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw() -> pd.DataFrame:\n",
    "    return pd.read_csv(raw_data_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-trash",
   "metadata": {},
   "source": [
    "### Get basic overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "impressed-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_overview():\n",
    "    return load_raw().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "appropriate-attack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29952 entries, 0 to 29951\n",
      "Data columns (total 48 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Date      29952 non-null  object \n",
      " 1   Name      29939 non-null  object \n",
      " 2   Team      29952 non-null  object \n",
      " 3   Opp       29952 non-null  object \n",
      " 4   FPTS      29952 non-null  float64\n",
      " 5   MP        29952 non-null  float64\n",
      " 6   FPTS/MP   29952 non-null  float64\n",
      " 7   Home      29952 non-null  int64  \n",
      " 8   W         29952 non-null  object \n",
      " 9   W_PTS     29952 non-null  int64  \n",
      " 10  L         29952 non-null  object \n",
      " 11  L_PTS     29952 non-null  int64  \n",
      " 12  Injury    29952 non-null  int64  \n",
      " 13  Starter   29952 non-null  int64  \n",
      " 14  FG        29952 non-null  float64\n",
      " 15  FGA       29952 non-null  float64\n",
      " 16  FG_perc   29952 non-null  float64\n",
      " 17  3P        29952 non-null  float64\n",
      " 18  3PA       29952 non-null  float64\n",
      " 19  3P_perc   29952 non-null  float64\n",
      " 20  FT        29952 non-null  float64\n",
      " 21  FTA       29952 non-null  float64\n",
      " 22  FT_perc   29952 non-null  float64\n",
      " 23  ORB       29952 non-null  float64\n",
      " 24  DRB       29952 non-null  float64\n",
      " 25  TRB       29952 non-null  float64\n",
      " 26  AST       29952 non-null  float64\n",
      " 27  STL       29952 non-null  float64\n",
      " 28  BLK       29952 non-null  float64\n",
      " 29  TOV       29952 non-null  float64\n",
      " 30  PF        29952 non-null  float64\n",
      " 31  PTS       29952 non-null  float64\n",
      " 32  +/-       29952 non-null  float64\n",
      " 33  TS_perc   29952 non-null  float64\n",
      " 34  eFG_perc  29952 non-null  float64\n",
      " 35  3PAr      29952 non-null  float64\n",
      " 36  FTr       29952 non-null  float64\n",
      " 37  ORB_perc  29952 non-null  float64\n",
      " 38  DRB_perc  29952 non-null  float64\n",
      " 39  TRB_perc  29952 non-null  float64\n",
      " 40  AST_perc  29952 non-null  float64\n",
      " 41  STL_perc  29952 non-null  float64\n",
      " 42  BLK_perc  29952 non-null  float64\n",
      " 43  TOV_perc  29952 non-null  float64\n",
      " 44  USG_perc  29952 non-null  float64\n",
      " 45  ORtg      29952 non-null  float64\n",
      " 46  DRtg      29952 non-null  float64\n",
      " 47  BPM       29952 non-null  float64\n",
      "dtypes: float64(37), int64(5), object(6)\n",
      "memory usage: 11.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-gnome",
   "metadata": {},
   "source": [
    "**Since I scraped this data myself, there should not be very many missing values, except on the rare occassion the scraper adds a blank space for a name after injuries and then fills the stats as if they were a player who DNP that game**\n",
    "</br>\n",
    "</br>\n",
    "Therefore, I know I need to drop these rows from the dataset. I will write a basic function to check if there are missing data or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "attached-fossil",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_missing_data(df) -> bool:\n",
    "    return df.dropna().shape != df.shape\n",
    "    \n",
    "#     return f'{\"No missing values anywhere\" if not is_missing_values(df) else \"Data is missing some values, need to fix\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dominant-phrase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contains_missing_data( load_raw() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-activity",
   "metadata": {},
   "source": [
    "#### clean_data():\n",
    " - load the raw data \n",
    " - do some basic cleaning, as described by comments within chain of pandas operations\n",
    " - save as a new file 'season-data-clean.csv' to se for the rest of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "diagnostic-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_path() -> str:\n",
    "    return raw_data_path().replace('raw', 'clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cellular-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data() -> None:\n",
    "    \n",
    "#     Columns must be renamed before using this\n",
    "#     Positive integers lt 255\n",
    "    uint_cols: tuple[int,...] = (\n",
    "        'home',\n",
    "        'starter',\n",
    "        'injury',\n",
    "        'w_pts',\n",
    "        'l_pts',\n",
    "        'fg',\n",
    "        'fga',\n",
    "        '3p',\n",
    "        '3pa',\n",
    "        'ft',\n",
    "        'fta',\n",
    "        'pts',\n",
    "        'ast',\n",
    "        'orb',\n",
    "        'drb',\n",
    "        'trb',\n",
    "        'stl',\n",
    "        'blk',\n",
    "        'tov',\n",
    "        'pf',\n",
    "        'ortg',\n",
    "        'drtg'\n",
    "    )\n",
    "        \n",
    "    rename_cols: dict[str,str] = {\n",
    "        'FPTS/MP': 'fppm',\n",
    "        '+/-': 'plus_minus',\n",
    "#         usage, effective field goal, and true shooting percentages dont have any similar stats, unlike field goal and field goal percentage\n",
    "#             can trim the '_perc' part off just these\n",
    "        'USG_perc': 'usg',\n",
    "        'eFG_perc': 'efg',\n",
    "        'TS_perc': 'ts',\n",
    "    }\n",
    "    \n",
    "    df: pd.DataFrame = (load_raw()\n",
    "#                         Get rid of rows containing null values\n",
    "                        .pipe( lambda df_: df_.loc[df_.isna().any(axis=1) == False] )\n",
    "#                         Rename certain columns directly so that they can be typed in df.col_name manner\n",
    "#                         and to avoid problems with subsequent step.\n",
    "                        .rename( rename_cols, axis=1 )\n",
    "#                         Convert all columns to lowercase, trim any possible blank spaces, and convert - to _\n",
    "                        .rename( columns=lambda col_name: col_name.lower().replace(' ', '').replace('-','_') )\n",
    "#                         Create new columns and correct types such that they are in optimal form\n",
    "#                             new columns: total_pts, pts_diff\n",
    "#                             uint8 --> integer column values < 255\n",
    "                        .assign(\n",
    "                            total_pts=lambda df_: df_.w_pts+df_.l_pts,\n",
    "                            # will need to correct for winners/losers\n",
    "                            pts_diff=lambda df_: df_.w_pts-df_.l_pts,\n",
    "                            **{c:lambda df_, c=c:df_[c].astype('uint8') for c in uint_cols},\n",
    "                               )\n",
    "#                         Get rid of all inactive players rows\n",
    "                        .pipe(lambda df_: df_.loc[df_['mp'] > 0.0])\n",
    "                       )\n",
    "    \n",
    "#     Correct the pts_diff column to account for if team lost by that much (cannot use conditional within assign command)\n",
    "    df.loc[df['team'] != df['w'], 'pts_diff'] *= -1\n",
    "    \n",
    "    df.to_csv(clean_data_path(), index=False)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acoustic-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean() -> pd.DataFrame:\n",
    "    return pd.read_csv(clean_data_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "exact-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acceptable-lucas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19002 entries, 0 to 19001\n",
      "Data columns (total 50 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   date        19002 non-null  object \n",
      " 1   name        19002 non-null  object \n",
      " 2   team        19002 non-null  object \n",
      " 3   opp         19002 non-null  object \n",
      " 4   fpts        19002 non-null  float64\n",
      " 5   mp          19002 non-null  float64\n",
      " 6   fppm        19002 non-null  float64\n",
      " 7   home        19002 non-null  int64  \n",
      " 8   w           19002 non-null  object \n",
      " 9   w_pts       19002 non-null  int64  \n",
      " 10  l           19002 non-null  object \n",
      " 11  l_pts       19002 non-null  int64  \n",
      " 12  injury      19002 non-null  int64  \n",
      " 13  starter     19002 non-null  int64  \n",
      " 14  fg          19002 non-null  int64  \n",
      " 15  fga         19002 non-null  int64  \n",
      " 16  fg_perc     19002 non-null  float64\n",
      " 17  3p          19002 non-null  int64  \n",
      " 18  3pa         19002 non-null  int64  \n",
      " 19  3p_perc     19002 non-null  float64\n",
      " 20  ft          19002 non-null  int64  \n",
      " 21  fta         19002 non-null  int64  \n",
      " 22  ft_perc     19002 non-null  float64\n",
      " 23  orb         19002 non-null  int64  \n",
      " 24  drb         19002 non-null  int64  \n",
      " 25  trb         19002 non-null  int64  \n",
      " 26  ast         19002 non-null  int64  \n",
      " 27  stl         19002 non-null  int64  \n",
      " 28  blk         19002 non-null  int64  \n",
      " 29  tov         19002 non-null  int64  \n",
      " 30  pf          19002 non-null  int64  \n",
      " 31  pts         19002 non-null  int64  \n",
      " 32  plus_minus  19002 non-null  float64\n",
      " 33  ts          19002 non-null  float64\n",
      " 34  efg         19002 non-null  float64\n",
      " 35  3par        19002 non-null  float64\n",
      " 36  ftr         19002 non-null  float64\n",
      " 37  orb_perc    19002 non-null  float64\n",
      " 38  drb_perc    19002 non-null  float64\n",
      " 39  trb_perc    19002 non-null  float64\n",
      " 40  ast_perc    19002 non-null  float64\n",
      " 41  stl_perc    19002 non-null  float64\n",
      " 42  blk_perc    19002 non-null  float64\n",
      " 43  tov_perc    19002 non-null  float64\n",
      " 44  usg         19002 non-null  float64\n",
      " 45  ortg        19002 non-null  int64  \n",
      " 46  drtg        19002 non-null  int64  \n",
      " 47  bpm         19002 non-null  float64\n",
      " 48  total_pts   19002 non-null  int64  \n",
      " 49  pts_diff    19002 non-null  int64  \n",
      "dtypes: float64(20), int64(24), object(6)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "load_clean().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-trinidad",
   "metadata": {},
   "source": [
    "#### Final check that all cleaning tasks came out as desired\n",
    "- No missing values in any rows\n",
    "- Columns all lowercase and any special formatting taken care of\n",
    "- Only specified columns for now\n",
    "- Only active players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "matched-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_check() -> None:\n",
    "#     asserts for all type of cleaning want to do\n",
    "    \n",
    "    clean_df: pd.DataFrame = load_clean()\n",
    "        \n",
    "    assert(not contains_missing_data(clean_df))\n",
    "    assert(not len([char for char in ''.join(clean_df.columns) if char.isupper() or char== '-' ]))\n",
    "    assert(not len(clean_df.loc[clean_df['mp'] == 0.0]))\n",
    "    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "extraordinary-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-munich",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
