{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "isolated-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-morocco",
   "metadata": {},
   "source": [
    "#### Programming Note:\n",
    "- I prefer to encapsulate everything within a function rather than have variables within just the notebook.\n",
    "- While I understand that this takes away from some of the perks of the sandbox environment of Jupyter Notebooks, I feel that maintaining the scope of data/variables in this way prevents issues further down the road, such as\n",
    "    - conflicting variables/variable names,\n",
    "    - unintended changes,\n",
    "    - functions confusing which data to use\n",
    "    - mutability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-kentucky",
   "metadata": {},
   "source": [
    "#### Data Note\n",
    "- I have chosen to undo some of the cleaning I perform in my webscraping package in order to demonstrate some common cleaning examples\n",
    "- By doing this, I can simulate likely requirements when dealing with unfamiliar/third-party data sources, such as eliminating null values and cleaning up columns/rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incorrect-solomon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_data_path() -> str:\n",
    "    return '/'.join([\n",
    "        os.getcwd().replace('src', 'data'),\n",
    "        'season-data-raw.csv'\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "official-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw() -> pd.DataFrame:\n",
    "    return pd.read_csv(raw_data_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-moment",
   "metadata": {},
   "source": [
    "### Get basic overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hawaiian-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_overview():\n",
    "    return load_raw().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tropical-wagner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32928 entries, 0 to 32927\n",
      "Data columns (total 48 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Date      32928 non-null  object \n",
      " 1   Name      32914 non-null  object \n",
      " 2   Team      32928 non-null  object \n",
      " 3   Opp       32928 non-null  object \n",
      " 4   FPTS      32928 non-null  float64\n",
      " 5   MP        32928 non-null  float64\n",
      " 6   FPTS/MP   32928 non-null  float64\n",
      " 7   Home      32928 non-null  int64  \n",
      " 8   W         32928 non-null  object \n",
      " 9   W_PTS     32928 non-null  int64  \n",
      " 10  L         32928 non-null  object \n",
      " 11  L_PTS     32928 non-null  int64  \n",
      " 12  Injury    32928 non-null  int64  \n",
      " 13  Starter   32928 non-null  int64  \n",
      " 14  FG        32928 non-null  float64\n",
      " 15  FGA       32928 non-null  float64\n",
      " 16  FG_perc   32928 non-null  float64\n",
      " 17  3P        32928 non-null  float64\n",
      " 18  3PA       32928 non-null  float64\n",
      " 19  3P_perc   32928 non-null  float64\n",
      " 20  FT        32928 non-null  float64\n",
      " 21  FTA       32928 non-null  float64\n",
      " 22  FT_perc   32928 non-null  float64\n",
      " 23  ORB       32928 non-null  float64\n",
      " 24  DRB       32928 non-null  float64\n",
      " 25  TRB       32928 non-null  float64\n",
      " 26  AST       32928 non-null  float64\n",
      " 27  STL       32928 non-null  float64\n",
      " 28  BLK       32928 non-null  float64\n",
      " 29  TOV       32928 non-null  float64\n",
      " 30  PF        32928 non-null  float64\n",
      " 31  PTS       32928 non-null  float64\n",
      " 32  +/-       32928 non-null  float64\n",
      " 33  TS_perc   32928 non-null  float64\n",
      " 34  eFG_perc  32928 non-null  float64\n",
      " 35  3PAr      32928 non-null  float64\n",
      " 36  FTr       32928 non-null  float64\n",
      " 37  ORB_perc  32928 non-null  float64\n",
      " 38  DRB_perc  32928 non-null  float64\n",
      " 39  TRB_perc  32928 non-null  float64\n",
      " 40  AST_perc  32928 non-null  float64\n",
      " 41  STL_perc  32928 non-null  float64\n",
      " 42  BLK_perc  32928 non-null  float64\n",
      " 43  TOV_perc  32928 non-null  float64\n",
      " 44  USG_perc  32928 non-null  float64\n",
      " 45  ORtg      32928 non-null  float64\n",
      " 46  DRtg      32928 non-null  float64\n",
      " 47  BPM       32928 non-null  float64\n",
      "dtypes: float64(37), int64(5), object(6)\n",
      "memory usage: 12.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-eligibility",
   "metadata": {},
   "source": [
    "**Since I scraped this data myself, there should not be very many missing values, except on the rare occassion the scraper adds a blank space for a name after injuries and then fills the stats as if they were a player who DNP that game**\n",
    "</br>\n",
    "</br>\n",
    "Therefore, I know I need to drop these rows from the dataset. I will write a basic function to check if there are missing data or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "exceptional-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_missing_data(df) -> bool:\n",
    "    return df.dropna().shape != df.shape\n",
    "    \n",
    "#     return f'{\"No missing values anywhere\" if not is_missing_values(df) else \"Data is missing some values, need to fix\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "special-lancaster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contains_missing_data( load_raw() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-berlin",
   "metadata": {},
   "source": [
    "#### clean_data():\n",
    " - load the raw data \n",
    " - do some basic cleaning, as described by comments within chain of pandas operations\n",
    " - save as a new file 'season-data-clean.csv' to se for the rest of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "irish-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_path() -> str:\n",
    "    return raw_data_path().replace('raw', 'clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "diverse-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data() -> None:\n",
    "    \n",
    "#     Columns must be renamed before using this\n",
    "#     Positive integers lt 255\n",
    "    uint_cols: tuple[int,...] = (\n",
    "        'home',\n",
    "        'starter',\n",
    "        'injury',\n",
    "        'w_pts',\n",
    "        'l_pts',\n",
    "        'fg',\n",
    "        'fga',\n",
    "        '3p',\n",
    "        '3pa',\n",
    "        'ft',\n",
    "        'fta',\n",
    "        'pts',\n",
    "        'ast',\n",
    "        'orb',\n",
    "        'drb',\n",
    "        'trb',\n",
    "        'stl',\n",
    "        'blk',\n",
    "        'tov',\n",
    "        'pf',\n",
    "        'ortg',\n",
    "        'drtg'\n",
    "    )\n",
    "        \n",
    "    rename_cols: dict[str,str] = {\n",
    "        'FPTS/MP': 'fppm',\n",
    "        '+/-': 'plus_minus',\n",
    "#         usage, effective field goal, and true shooting percentages dont have any similar stats, unlike field goal and field goal percentage\n",
    "#             can trim the '_perc' part off just these\n",
    "        'USG_perc': 'usg',\n",
    "        'eFG_perc': 'efg',\n",
    "        'TS_perc': 'ts',\n",
    "    }\n",
    "    \n",
    "    df: pd.DataFrame = (load_raw()\n",
    "#                         Get rid of rows containing null values\n",
    "                        .pipe( lambda df_: df_.loc[df_.isna().any(axis=1) == False] )\n",
    "#                         Rename certain columns directly so that they can be typed in df.col_name manner\n",
    "#                         and to avoid problems with subsequent step.\n",
    "                        .rename( rename_cols, axis=1 )\n",
    "#                         Convert all columns to lowercase, trim any possible blank spaces, and convert - to _\n",
    "                        .rename( columns=lambda col_name: col_name.lower().replace(' ', '').replace('-','_') )\n",
    "#                         Create new columns and correct types such that they are in optimal form\n",
    "#                             new columns: total_pts, pts_diff\n",
    "#                             uint8 --> integer column values < 255\n",
    "                        .assign(\n",
    "                            total_pts=lambda df_: df_.w_pts+df_.l_pts,\n",
    "                            # will need to correct for winners/losers\n",
    "                            pts_diff=lambda df_: df_.w_pts-df_.l_pts,\n",
    "                            **{c:lambda df_, c=c:df_[c].astype('uint8') for c in uint_cols},\n",
    "                               )\n",
    "#                         Get rid of all inactive players rows\n",
    "                        .pipe(lambda df_: df_.loc[df_['mp'] > 0.0])\n",
    "                       )\n",
    "    \n",
    "#     Correct the pts_diff column to account for if team lost by that much (cannot use conditional within assign command)\n",
    "    df.loc[df['team'] != df['w'], 'pts_diff'] *= -1\n",
    "    \n",
    "    df.to_csv(clean_data_path(), index=False)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "controlling-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean() -> pd.DataFrame:\n",
    "    return pd.read_csv(clean_data_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "informed-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "phantom-graph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20876 entries, 0 to 20875\n",
      "Data columns (total 50 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   date        20876 non-null  object \n",
      " 1   name        20876 non-null  object \n",
      " 2   team        20876 non-null  object \n",
      " 3   opp         20876 non-null  object \n",
      " 4   fpts        20876 non-null  float64\n",
      " 5   mp          20876 non-null  float64\n",
      " 6   fppm        20876 non-null  float64\n",
      " 7   home        20876 non-null  int64  \n",
      " 8   w           20876 non-null  object \n",
      " 9   w_pts       20876 non-null  int64  \n",
      " 10  l           20876 non-null  object \n",
      " 11  l_pts       20876 non-null  int64  \n",
      " 12  injury      20876 non-null  int64  \n",
      " 13  starter     20876 non-null  int64  \n",
      " 14  fg          20876 non-null  int64  \n",
      " 15  fga         20876 non-null  int64  \n",
      " 16  fg_perc     20876 non-null  float64\n",
      " 17  3p          20876 non-null  int64  \n",
      " 18  3pa         20876 non-null  int64  \n",
      " 19  3p_perc     20876 non-null  float64\n",
      " 20  ft          20876 non-null  int64  \n",
      " 21  fta         20876 non-null  int64  \n",
      " 22  ft_perc     20876 non-null  float64\n",
      " 23  orb         20876 non-null  int64  \n",
      " 24  drb         20876 non-null  int64  \n",
      " 25  trb         20876 non-null  int64  \n",
      " 26  ast         20876 non-null  int64  \n",
      " 27  stl         20876 non-null  int64  \n",
      " 28  blk         20876 non-null  int64  \n",
      " 29  tov         20876 non-null  int64  \n",
      " 30  pf          20876 non-null  int64  \n",
      " 31  pts         20876 non-null  int64  \n",
      " 32  plus_minus  20876 non-null  float64\n",
      " 33  ts          20876 non-null  float64\n",
      " 34  efg         20876 non-null  float64\n",
      " 35  3par        20876 non-null  float64\n",
      " 36  ftr         20876 non-null  float64\n",
      " 37  orb_perc    20876 non-null  float64\n",
      " 38  drb_perc    20876 non-null  float64\n",
      " 39  trb_perc    20876 non-null  float64\n",
      " 40  ast_perc    20876 non-null  float64\n",
      " 41  stl_perc    20876 non-null  float64\n",
      " 42  blk_perc    20876 non-null  float64\n",
      " 43  tov_perc    20876 non-null  float64\n",
      " 44  usg         20876 non-null  float64\n",
      " 45  ortg        20876 non-null  int64  \n",
      " 46  drtg        20876 non-null  int64  \n",
      " 47  bpm         20876 non-null  float64\n",
      " 48  total_pts   20876 non-null  int64  \n",
      " 49  pts_diff    20876 non-null  int64  \n",
      "dtypes: float64(20), int64(24), object(6)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "load_clean().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-carbon",
   "metadata": {},
   "source": [
    "#### Final check that all cleaning tasks came out as desired\n",
    "- No missing values in any rows\n",
    "- Columns all lowercase and any special formatting taken care of\n",
    "- Only specified columns for now\n",
    "- Only active players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "grave-standing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_check() -> None:\n",
    "#     asserts for all type of cleaning want to do\n",
    "    \n",
    "    clean_df: pd.DataFrame = load_clean()\n",
    "        \n",
    "    last_date: str = tuple(clean_df\n",
    "                           ['date']\n",
    "                           .drop_duplicates()\n",
    "                           .sort_values()\n",
    "                          )[-1]\n",
    "    \n",
    "    print(f'Last date: {last_date}\\n')\n",
    "    assert(not contains_missing_data(clean_df))\n",
    "    assert(not len([char for char in ''.join(clean_df.columns) if char.isupper() or char== '-' ]))\n",
    "    assert(not len(clean_df.loc[clean_df['mp'] == 0.0]))\n",
    "    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "included-region",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last date: 2023-03-08\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-saver",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
