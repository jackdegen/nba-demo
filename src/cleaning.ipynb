{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decimal-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-pride",
   "metadata": {},
   "source": [
    "#### Programming Note:\n",
    "- I prefer to encapsulate everything within a function rather than have variables within just the notebook.\n",
    "- While I understand that this takes away from some of the perks of the sandbox environment of Jupyter Notebooks, I feel that maintaining the scope of data/variables in this way prevents issues further down the road, such as\n",
    "    - conflicting variables/variable names,\n",
    "    - unintended changes,\n",
    "    - functions confusing which data to use\n",
    "    - mutability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-investor",
   "metadata": {},
   "source": [
    "#### Data Note\n",
    "- I have chosen to undo some of the cleaning I perform in my webscraping package in order to demonstrate some common cleaning examples\n",
    "- By doing this, I can simulate likely requirements when dealing with unfamiliar/third-party data sources, such as eliminating null values and cleaning up columns/rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "attached-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_data_path() -> str:\n",
    "    return '/'.join([\n",
    "        os.getcwd().replace('src', 'data'),\n",
    "        'season-data-raw.csv'\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fitted-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw() -> pd.DataFrame:\n",
    "    return pd.read_csv(raw_data_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-activity",
   "metadata": {},
   "source": [
    "### Get basic overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "parliamentary-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_overview():\n",
    "    return load_raw().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "selected-enzyme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34089 entries, 0 to 34088\n",
      "Data columns (total 48 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Date      34089 non-null  object \n",
      " 1   Name      34075 non-null  object \n",
      " 2   Team      34089 non-null  object \n",
      " 3   Opp       34089 non-null  object \n",
      " 4   FPTS      34089 non-null  float64\n",
      " 5   MP        34089 non-null  float64\n",
      " 6   FPTS/MP   34089 non-null  float64\n",
      " 7   Home      34089 non-null  int64  \n",
      " 8   W         34089 non-null  object \n",
      " 9   W_PTS     34089 non-null  int64  \n",
      " 10  L         34089 non-null  object \n",
      " 11  L_PTS     34089 non-null  int64  \n",
      " 12  Injury    34089 non-null  int64  \n",
      " 13  Starter   34089 non-null  int64  \n",
      " 14  FG        34089 non-null  float64\n",
      " 15  FGA       34089 non-null  float64\n",
      " 16  FG_perc   34089 non-null  float64\n",
      " 17  3P        34089 non-null  float64\n",
      " 18  3PA       34089 non-null  float64\n",
      " 19  3P_perc   34089 non-null  float64\n",
      " 20  FT        34089 non-null  float64\n",
      " 21  FTA       34089 non-null  float64\n",
      " 22  FT_perc   34089 non-null  float64\n",
      " 23  ORB       34089 non-null  float64\n",
      " 24  DRB       34089 non-null  float64\n",
      " 25  TRB       34089 non-null  float64\n",
      " 26  AST       34089 non-null  float64\n",
      " 27  STL       34089 non-null  float64\n",
      " 28  BLK       34089 non-null  float64\n",
      " 29  TOV       34089 non-null  float64\n",
      " 30  PF        34089 non-null  float64\n",
      " 31  PTS       34089 non-null  float64\n",
      " 32  +/-       34089 non-null  float64\n",
      " 33  TS_perc   34089 non-null  float64\n",
      " 34  eFG_perc  34089 non-null  float64\n",
      " 35  3PAr      34089 non-null  float64\n",
      " 36  FTr       34089 non-null  float64\n",
      " 37  ORB_perc  34089 non-null  float64\n",
      " 38  DRB_perc  34089 non-null  float64\n",
      " 39  TRB_perc  34089 non-null  float64\n",
      " 40  AST_perc  34089 non-null  float64\n",
      " 41  STL_perc  34089 non-null  float64\n",
      " 42  BLK_perc  34089 non-null  float64\n",
      " 43  TOV_perc  34089 non-null  float64\n",
      " 44  USG_perc  34089 non-null  float64\n",
      " 45  ORtg      34089 non-null  float64\n",
      " 46  DRtg      34089 non-null  float64\n",
      " 47  BPM       34089 non-null  float64\n",
      "dtypes: float64(37), int64(5), object(6)\n",
      "memory usage: 12.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-leather",
   "metadata": {},
   "source": [
    "**Since I scraped this data myself, there should not be very many missing values, except on the rare occassion the scraper adds a blank space for a name after injuries and then fills the stats as if they were a player who DNP that game**\n",
    "</br>\n",
    "</br>\n",
    "Therefore, I know I need to drop these rows from the dataset. I will write a basic function to check if there are missing data or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "consolidated-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_missing_data(df) -> bool:\n",
    "    return df.dropna().shape != df.shape\n",
    "    \n",
    "#     return f'{\"No missing values anywhere\" if not is_missing_values(df) else \"Data is missing some values, need to fix\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "diagnostic-hardware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contains_missing_data( load_raw() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-found",
   "metadata": {},
   "source": [
    "#### clean_data():\n",
    " - load the raw data \n",
    " - do some basic cleaning, as described by comments within chain of pandas operations\n",
    " - save as a new file 'season-data-clean.csv' to se for the rest of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "independent-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_path() -> str:\n",
    "    return raw_data_path().replace('raw', 'clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dress-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data() -> None:\n",
    "    \n",
    "#     Columns must be renamed before using this\n",
    "#     Positive integers lt 255\n",
    "    uint_cols: tuple[int,...] = (\n",
    "        'home',\n",
    "        'starter',\n",
    "        'injury',\n",
    "        'w_pts',\n",
    "        'l_pts',\n",
    "        'fg',\n",
    "        'fga',\n",
    "        '3p',\n",
    "        '3pa',\n",
    "        'ft',\n",
    "        'fta',\n",
    "        'pts',\n",
    "        'ast',\n",
    "        'orb',\n",
    "        'drb',\n",
    "        'trb',\n",
    "        'stl',\n",
    "        'blk',\n",
    "        'tov',\n",
    "        'pf',\n",
    "        'ortg',\n",
    "        'drtg'\n",
    "    )\n",
    "        \n",
    "    rename_cols: dict[str,str] = {\n",
    "        'FPTS/MP': 'fppm',\n",
    "        '+/-': 'plus_minus',\n",
    "#         usage, effective field goal, and true shooting percentages dont have any similar stats, unlike field goal and field goal percentage\n",
    "#             can trim the '_perc' part off just these\n",
    "        'USG_perc': 'usg',\n",
    "        'eFG_perc': 'efg',\n",
    "        'TS_perc': 'ts',\n",
    "    }\n",
    "    \n",
    "    df: pd.DataFrame = (load_raw()\n",
    "#                         Get rid of rows containing null values\n",
    "                        .pipe( lambda df_: df_.loc[df_.isna().any(axis=1) == False] )\n",
    "#                         Rename certain columns directly so that they can be typed in df.col_name manner\n",
    "#                         and to avoid problems with subsequent step.\n",
    "                        .rename( rename_cols, axis=1 )\n",
    "#                         Convert all columns to lowercase, trim any possible blank spaces, and convert - to _\n",
    "                        .rename( columns=lambda col_name: col_name.lower().replace(' ', '').replace('-','_') )\n",
    "#                         Create new columns and correct types such that they are in optimal form\n",
    "#                             new columns: total_pts, pts_diff\n",
    "#                             uint8 --> integer column values < 255\n",
    "                        .assign(\n",
    "                            total_pts=lambda df_: df_.w_pts+df_.l_pts,\n",
    "                            # will need to correct for winners/losers\n",
    "                            pts_diff=lambda df_: df_.w_pts-df_.l_pts,\n",
    "                            **{c:lambda df_, c=c:df_[c].astype('uint8') for c in uint_cols},\n",
    "                               )\n",
    "#                         Get rid of all inactive players rows\n",
    "                        .pipe(lambda df_: df_.loc[df_['mp'] > 0.0])\n",
    "                       )\n",
    "    \n",
    "#     Correct the pts_diff column to account for if team lost by that much (cannot use conditional within assign command)\n",
    "    df.loc[df['team'] != df['w'], 'pts_diff'] *= -1\n",
    "    \n",
    "    df.to_csv(clean_data_path(), index=False)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eleven-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean() -> pd.DataFrame:\n",
    "    return pd.read_csv(clean_data_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "billion-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "middle-retreat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21588 entries, 0 to 21587\n",
      "Data columns (total 50 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   date        21588 non-null  object \n",
      " 1   name        21588 non-null  object \n",
      " 2   team        21588 non-null  object \n",
      " 3   opp         21588 non-null  object \n",
      " 4   fpts        21588 non-null  float64\n",
      " 5   mp          21588 non-null  float64\n",
      " 6   fppm        21588 non-null  float64\n",
      " 7   home        21588 non-null  int64  \n",
      " 8   w           21588 non-null  object \n",
      " 9   w_pts       21588 non-null  int64  \n",
      " 10  l           21588 non-null  object \n",
      " 11  l_pts       21588 non-null  int64  \n",
      " 12  injury      21588 non-null  int64  \n",
      " 13  starter     21588 non-null  int64  \n",
      " 14  fg          21588 non-null  int64  \n",
      " 15  fga         21588 non-null  int64  \n",
      " 16  fg_perc     21588 non-null  float64\n",
      " 17  3p          21588 non-null  int64  \n",
      " 18  3pa         21588 non-null  int64  \n",
      " 19  3p_perc     21588 non-null  float64\n",
      " 20  ft          21588 non-null  int64  \n",
      " 21  fta         21588 non-null  int64  \n",
      " 22  ft_perc     21588 non-null  float64\n",
      " 23  orb         21588 non-null  int64  \n",
      " 24  drb         21588 non-null  int64  \n",
      " 25  trb         21588 non-null  int64  \n",
      " 26  ast         21588 non-null  int64  \n",
      " 27  stl         21588 non-null  int64  \n",
      " 28  blk         21588 non-null  int64  \n",
      " 29  tov         21588 non-null  int64  \n",
      " 30  pf          21588 non-null  int64  \n",
      " 31  pts         21588 non-null  int64  \n",
      " 32  plus_minus  21588 non-null  float64\n",
      " 33  ts          21588 non-null  float64\n",
      " 34  efg         21588 non-null  float64\n",
      " 35  3par        21588 non-null  float64\n",
      " 36  ftr         21588 non-null  float64\n",
      " 37  orb_perc    21588 non-null  float64\n",
      " 38  drb_perc    21588 non-null  float64\n",
      " 39  trb_perc    21588 non-null  float64\n",
      " 40  ast_perc    21588 non-null  float64\n",
      " 41  stl_perc    21588 non-null  float64\n",
      " 42  blk_perc    21588 non-null  float64\n",
      " 43  tov_perc    21588 non-null  float64\n",
      " 44  usg         21588 non-null  float64\n",
      " 45  ortg        21588 non-null  int64  \n",
      " 46  drtg        21588 non-null  int64  \n",
      " 47  bpm         21588 non-null  float64\n",
      " 48  total_pts   21588 non-null  int64  \n",
      " 49  pts_diff    21588 non-null  int64  \n",
      "dtypes: float64(20), int64(24), object(6)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "load_clean().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-calgary",
   "metadata": {},
   "source": [
    "#### Final check that all cleaning tasks came out as desired\n",
    "- No missing values in any rows\n",
    "- Columns all lowercase and any special formatting taken care of\n",
    "- Only specified columns for now\n",
    "- Only active players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "streaming-prize",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_check() -> None:\n",
    "#     asserts for all type of cleaning want to do\n",
    "    \n",
    "    clean_df: pd.DataFrame = load_clean()\n",
    "        \n",
    "    last_date: str = tuple(clean_df\n",
    "                           ['date']\n",
    "                           .drop_duplicates()\n",
    "                           .sort_values()\n",
    "                          )[-1]\n",
    "    \n",
    "    print(f'Last date: {last_date}\\n')\n",
    "    assert(not contains_missing_data(clean_df))\n",
    "    assert(not len([char for char in ''.join(clean_df.columns) if char.isupper() or char == '-' ]))\n",
    "    assert(not len(clean_df.loc[clean_df['mp'] == 0.0]))\n",
    "    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "broadband-little",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last date: 2023-03-13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-bonus",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
