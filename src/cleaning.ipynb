{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "amateur-surge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "# from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import matplotlib.style as style\n",
    "style.use('seaborn-colorblind')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-mailman",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "- I prefer to encapsulate everything within a function rather than have variables within just the notebook.\n",
    "- While I understand that this takes away from some of the perks of the sandbox environment of Jupyter Notebooks, I feel that maintaining the scope of data/variables in this way prevents issues further down the road, such as\n",
    "    - conflicting variables/variable names,\n",
    "    - unintended changes,\n",
    "    - functions confusing which data to use\n",
    "    - mutability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "outer-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_data_path() -> str:\n",
    "    return '/'.join([\n",
    "        os.getcwd().replace('src', 'data'),\n",
    "        'season-data-raw.csv'\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "international-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw() -> pd.DataFrame:\n",
    "    return pd.read_csv(raw_data_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-blond",
   "metadata": {},
   "source": [
    "### Get basic overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nuclear-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_overview():\n",
    "    return (load_raw()\n",
    "            .info()\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "minute-lightweight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28448 entries, 0 to 28447\n",
      "Data columns (total 48 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Date      28448 non-null  object \n",
      " 1   Name      28436 non-null  object \n",
      " 2   Team      28448 non-null  object \n",
      " 3   Opp       28448 non-null  object \n",
      " 4   FPTS      28448 non-null  float64\n",
      " 5   MP        28448 non-null  float64\n",
      " 6   FPTS/MP   28448 non-null  float64\n",
      " 7   Home      28448 non-null  int64  \n",
      " 8   W         28448 non-null  object \n",
      " 9   W_PTS     28448 non-null  int64  \n",
      " 10  L         28448 non-null  object \n",
      " 11  L_PTS     28448 non-null  int64  \n",
      " 12  Injury    28448 non-null  int64  \n",
      " 13  Starter   28448 non-null  int64  \n",
      " 14  FG        28448 non-null  float64\n",
      " 15  FGA       28448 non-null  float64\n",
      " 16  FG_perc   28448 non-null  float64\n",
      " 17  3P        28448 non-null  float64\n",
      " 18  3PA       28448 non-null  float64\n",
      " 19  3P_perc   28448 non-null  float64\n",
      " 20  FT        28448 non-null  float64\n",
      " 21  FTA       28448 non-null  float64\n",
      " 22  FT_perc   28448 non-null  float64\n",
      " 23  ORB       28448 non-null  float64\n",
      " 24  DRB       28448 non-null  float64\n",
      " 25  TRB       28448 non-null  float64\n",
      " 26  AST       28448 non-null  float64\n",
      " 27  STL       28448 non-null  float64\n",
      " 28  BLK       28448 non-null  float64\n",
      " 29  TOV       28448 non-null  float64\n",
      " 30  PF        28448 non-null  float64\n",
      " 31  PTS       28448 non-null  float64\n",
      " 32  +/-       28448 non-null  float64\n",
      " 33  TS_perc   28448 non-null  float64\n",
      " 34  eFG_perc  28448 non-null  float64\n",
      " 35  3PAr      28448 non-null  float64\n",
      " 36  FTr       28448 non-null  float64\n",
      " 37  ORB_perc  28448 non-null  float64\n",
      " 38  DRB_perc  28448 non-null  float64\n",
      " 39  TRB_perc  28448 non-null  float64\n",
      " 40  AST_perc  28448 non-null  float64\n",
      " 41  STL_perc  28448 non-null  float64\n",
      " 42  BLK_perc  28448 non-null  float64\n",
      " 43  TOV_perc  28448 non-null  float64\n",
      " 44  USG_perc  28448 non-null  float64\n",
      " 45  ORtg      28448 non-null  float64\n",
      " 46  DRtg      28448 non-null  float64\n",
      " 47  BPM       28448 non-null  float64\n",
      "dtypes: float64(37), int64(5), object(6)\n",
      "memory usage: 10.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-harvard",
   "metadata": {},
   "source": [
    "**As one can see, there are 48 columns and 28448 rows. Since I scraped this data myself, there should not be very many missing values, except on the rare occassion the scraper adds a blank space for a name after injuries and then fills the stats as if they were a player who DNP that game**\n",
    "</br>\n",
    "</br>\n",
    "Therefore, I know I need to drop these rows from the dataset. I will write a basic function to check if there are missing data or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "resident-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_missing(df) -> bool:\n",
    "    return df.dropna().shape == df.shape\n",
    "    \n",
    "#     return f'{\"No missing values anywhere\" if not is_missing_values(df) else \"Data is missing some values, need to fix\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "thirty-leonard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_missing( load_raw() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-application",
   "metadata": {},
   "source": [
    "#### clean_data():\n",
    " - load the raw data \n",
    " - do some basic cleaning, including dropping rows with missing values\n",
    " - save as a new file 'season-data-clean.csv' to se for the rest of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "collectible-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_path() -> str:\n",
    "    return raw_data_path().replace('raw', 'clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sustained-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data() -> None:\n",
    "    \n",
    "    df: pd.DataFrame = (load_raw()\n",
    "                        .pipe(lambda df_: df_.loc[df_.isna().any(axis=1) == False])\n",
    "                       )\n",
    "        \n",
    "    df.to_csv(clean_data_path(), index=False)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "miniature-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean() -> pd.DataFrame:\n",
    "    return pd.read_csv(clean_data_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-investor",
   "metadata": {},
   "source": [
    "#### Final check that all cleaning tasks came out as desired\n",
    "- No missing values in any rows\n",
    "- Columns all lowercase and any special formatting taken care of\n",
    "- Only specified columns for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "arranged-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_check() -> None:\n",
    "#     asserts for all type of cleaning want to do\n",
    "    \n",
    "    clean_df: pd.DataFrame = load_clean()\n",
    "    \n",
    "    assert(no_missing(clean_df))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "protective-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-kruger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
