{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "medium-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-hungary",
   "metadata": {},
   "source": [
    "#### Programming Note:\n",
    "- I prefer to encapsulate everything within a function rather than have variables within just the notebook.\n",
    "- While I understand that this takes away from some of the perks of the sandbox environment of Jupyter Notebooks, I feel that maintaining the scope of data/variables in this way prevents issues further down the road, such as\n",
    "    - conflicting variables/variable names,\n",
    "    - unintended changes,\n",
    "    - functions confusing which data to use\n",
    "    - mutability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-archives",
   "metadata": {},
   "source": [
    "#### Data Note\n",
    "- I have chosen to undo some of the cleaning I perform in my webscraping package in order to demonstrate some common cleaning examples\n",
    "- By doing this, I can simulate likely requirements when dealing with unfamiliar/third-party data sources, such as eliminating null values and cleaning up columns/rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "following-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_data_path() -> str:\n",
    "    return '/'.join([\n",
    "        os.getcwd().replace('src', 'data'),\n",
    "        'season-data-raw.csv'\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "disabled-genome",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw() -> pd.DataFrame:\n",
    "    return pd.read_csv(raw_data_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-median",
   "metadata": {},
   "source": [
    "### Get basic overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "blank-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_overview():\n",
    "    return load_raw().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sophisticated-ordinance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30942 entries, 0 to 30941\n",
      "Data columns (total 48 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Date      30942 non-null  object \n",
      " 1   Name      30928 non-null  object \n",
      " 2   Team      30942 non-null  object \n",
      " 3   Opp       30942 non-null  object \n",
      " 4   FPTS      30942 non-null  float64\n",
      " 5   MP        30942 non-null  float64\n",
      " 6   FPTS/MP   30942 non-null  float64\n",
      " 7   Home      30942 non-null  int64  \n",
      " 8   W         30942 non-null  object \n",
      " 9   W_PTS     30942 non-null  int64  \n",
      " 10  L         30942 non-null  object \n",
      " 11  L_PTS     30942 non-null  int64  \n",
      " 12  Injury    30942 non-null  int64  \n",
      " 13  Starter   30942 non-null  int64  \n",
      " 14  FG        30942 non-null  float64\n",
      " 15  FGA       30942 non-null  float64\n",
      " 16  FG_perc   30942 non-null  float64\n",
      " 17  3P        30942 non-null  float64\n",
      " 18  3PA       30942 non-null  float64\n",
      " 19  3P_perc   30942 non-null  float64\n",
      " 20  FT        30942 non-null  float64\n",
      " 21  FTA       30942 non-null  float64\n",
      " 22  FT_perc   30942 non-null  float64\n",
      " 23  ORB       30942 non-null  float64\n",
      " 24  DRB       30942 non-null  float64\n",
      " 25  TRB       30942 non-null  float64\n",
      " 26  AST       30942 non-null  float64\n",
      " 27  STL       30942 non-null  float64\n",
      " 28  BLK       30942 non-null  float64\n",
      " 29  TOV       30942 non-null  float64\n",
      " 30  PF        30942 non-null  float64\n",
      " 31  PTS       30942 non-null  float64\n",
      " 32  +/-       30942 non-null  float64\n",
      " 33  TS_perc   30942 non-null  float64\n",
      " 34  eFG_perc  30942 non-null  float64\n",
      " 35  3PAr      30942 non-null  float64\n",
      " 36  FTr       30942 non-null  float64\n",
      " 37  ORB_perc  30942 non-null  float64\n",
      " 38  DRB_perc  30942 non-null  float64\n",
      " 39  TRB_perc  30942 non-null  float64\n",
      " 40  AST_perc  30942 non-null  float64\n",
      " 41  STL_perc  30942 non-null  float64\n",
      " 42  BLK_perc  30942 non-null  float64\n",
      " 43  TOV_perc  30942 non-null  float64\n",
      " 44  USG_perc  30942 non-null  float64\n",
      " 45  ORtg      30942 non-null  float64\n",
      " 46  DRtg      30942 non-null  float64\n",
      " 47  BPM       30942 non-null  float64\n",
      "dtypes: float64(37), int64(5), object(6)\n",
      "memory usage: 11.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-preview",
   "metadata": {},
   "source": [
    "**Since I scraped this data myself, there should not be very many missing values, except on the rare occassion the scraper adds a blank space for a name after injuries and then fills the stats as if they were a player who DNP that game**\n",
    "</br>\n",
    "</br>\n",
    "Therefore, I know I need to drop these rows from the dataset. I will write a basic function to check if there are missing data or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "facial-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_missing_data(df) -> bool:\n",
    "    return df.dropna().shape != df.shape\n",
    "    \n",
    "#     return f'{\"No missing values anywhere\" if not is_missing_values(df) else \"Data is missing some values, need to fix\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efficient-buffalo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contains_missing_data( load_raw() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-mixture",
   "metadata": {},
   "source": [
    "#### clean_data():\n",
    " - load the raw data \n",
    " - do some basic cleaning, as described by comments within chain of pandas operations\n",
    " - save as a new file 'season-data-clean.csv' to se for the rest of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "successful-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_path() -> str:\n",
    "    return raw_data_path().replace('raw', 'clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "medical-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data() -> None:\n",
    "    \n",
    "#     Columns must be renamed before using this\n",
    "#     Positive integers lt 255\n",
    "    uint_cols: tuple[int,...] = (\n",
    "        'home',\n",
    "        'starter',\n",
    "        'injury',\n",
    "        'w_pts',\n",
    "        'l_pts',\n",
    "        'fg',\n",
    "        'fga',\n",
    "        '3p',\n",
    "        '3pa',\n",
    "        'ft',\n",
    "        'fta',\n",
    "        'pts',\n",
    "        'ast',\n",
    "        'orb',\n",
    "        'drb',\n",
    "        'trb',\n",
    "        'stl',\n",
    "        'blk',\n",
    "        'tov',\n",
    "        'pf',\n",
    "        'ortg',\n",
    "        'drtg'\n",
    "    )\n",
    "        \n",
    "    rename_cols: dict[str,str] = {\n",
    "        'FPTS/MP': 'fppm',\n",
    "        '+/-': 'plus_minus',\n",
    "#         usage, effective field goal, and true shooting percentages dont have any similar stats, unlike field goal and field goal percentage\n",
    "#             can trim the '_perc' part off just these\n",
    "        'USG_perc': 'usg',\n",
    "        'eFG_perc': 'efg',\n",
    "        'TS_perc': 'ts',\n",
    "    }\n",
    "    \n",
    "    df: pd.DataFrame = (load_raw()\n",
    "#                         Get rid of rows containing null values\n",
    "                        .pipe( lambda df_: df_.loc[df_.isna().any(axis=1) == False] )\n",
    "#                         Rename certain columns directly so that they can be typed in df.col_name manner\n",
    "#                         and to avoid problems with subsequent step.\n",
    "                        .rename( rename_cols, axis=1 )\n",
    "#                         Convert all columns to lowercase, trim any possible blank spaces, and convert - to _\n",
    "                        .rename( columns=lambda col_name: col_name.lower().replace(' ', '').replace('-','_') )\n",
    "#                         Create new columns and correct types such that they are in optimal form\n",
    "#                             new columns: total_pts, pts_diff\n",
    "#                             uint8 --> integer column values < 255\n",
    "                        .assign(\n",
    "                            total_pts=lambda df_: df_.w_pts+df_.l_pts,\n",
    "                            # will need to correct for winners/losers\n",
    "                            pts_diff=lambda df_: df_.w_pts-df_.l_pts,\n",
    "                            **{c:lambda df_, c=c:df_[c].astype('uint8') for c in uint_cols},\n",
    "                               )\n",
    "#                         Get rid of all inactive players rows\n",
    "                        .pipe(lambda df_: df_.loc[df_['mp'] > 0.0])\n",
    "                       )\n",
    "    \n",
    "#     Correct the pts_diff column to account for if team lost by that much (cannot use conditional within assign command)\n",
    "    df.loc[df['team'] != df['w'], 'pts_diff'] *= -1\n",
    "    \n",
    "    df.to_csv(clean_data_path(), index=False)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "difficult-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean() -> pd.DataFrame:\n",
    "    return pd.read_csv(clean_data_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "continuous-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "devoted-summit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19641 entries, 0 to 19640\n",
      "Data columns (total 50 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   date        19641 non-null  object \n",
      " 1   name        19641 non-null  object \n",
      " 2   team        19641 non-null  object \n",
      " 3   opp         19641 non-null  object \n",
      " 4   fpts        19641 non-null  float64\n",
      " 5   mp          19641 non-null  float64\n",
      " 6   fppm        19641 non-null  float64\n",
      " 7   home        19641 non-null  int64  \n",
      " 8   w           19641 non-null  object \n",
      " 9   w_pts       19641 non-null  int64  \n",
      " 10  l           19641 non-null  object \n",
      " 11  l_pts       19641 non-null  int64  \n",
      " 12  injury      19641 non-null  int64  \n",
      " 13  starter     19641 non-null  int64  \n",
      " 14  fg          19641 non-null  int64  \n",
      " 15  fga         19641 non-null  int64  \n",
      " 16  fg_perc     19641 non-null  float64\n",
      " 17  3p          19641 non-null  int64  \n",
      " 18  3pa         19641 non-null  int64  \n",
      " 19  3p_perc     19641 non-null  float64\n",
      " 20  ft          19641 non-null  int64  \n",
      " 21  fta         19641 non-null  int64  \n",
      " 22  ft_perc     19641 non-null  float64\n",
      " 23  orb         19641 non-null  int64  \n",
      " 24  drb         19641 non-null  int64  \n",
      " 25  trb         19641 non-null  int64  \n",
      " 26  ast         19641 non-null  int64  \n",
      " 27  stl         19641 non-null  int64  \n",
      " 28  blk         19641 non-null  int64  \n",
      " 29  tov         19641 non-null  int64  \n",
      " 30  pf          19641 non-null  int64  \n",
      " 31  pts         19641 non-null  int64  \n",
      " 32  plus_minus  19641 non-null  float64\n",
      " 33  ts          19641 non-null  float64\n",
      " 34  efg         19641 non-null  float64\n",
      " 35  3par        19641 non-null  float64\n",
      " 36  ftr         19641 non-null  float64\n",
      " 37  orb_perc    19641 non-null  float64\n",
      " 38  drb_perc    19641 non-null  float64\n",
      " 39  trb_perc    19641 non-null  float64\n",
      " 40  ast_perc    19641 non-null  float64\n",
      " 41  stl_perc    19641 non-null  float64\n",
      " 42  blk_perc    19641 non-null  float64\n",
      " 43  tov_perc    19641 non-null  float64\n",
      " 44  usg         19641 non-null  float64\n",
      " 45  ortg        19641 non-null  int64  \n",
      " 46  drtg        19641 non-null  int64  \n",
      " 47  bpm         19641 non-null  float64\n",
      " 48  total_pts   19641 non-null  int64  \n",
      " 49  pts_diff    19641 non-null  int64  \n",
      "dtypes: float64(20), int64(24), object(6)\n",
      "memory usage: 7.5+ MB\n"
     ]
    }
   ],
   "source": [
    "load_clean().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-alberta",
   "metadata": {},
   "source": [
    "#### Final check that all cleaning tasks came out as desired\n",
    "- No missing values in any rows\n",
    "- Columns all lowercase and any special formatting taken care of\n",
    "- Only specified columns for now\n",
    "- Only active players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "identified-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_check() -> None:\n",
    "#     asserts for all type of cleaning want to do\n",
    "    \n",
    "    clean_df: pd.DataFrame = load_clean()\n",
    "        \n",
    "    assert(not contains_missing_data(clean_df))\n",
    "    assert(not len([char for char in ''.join(clean_df.columns) if char.isupper() or char== '-' ]))\n",
    "    assert(not len(clean_df.loc[clean_df['mp'] == 0.0]))\n",
    "    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "smooth-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e94fbdf-a09e-4429-9ec6-09715d485c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
