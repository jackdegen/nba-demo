{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "excited-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-drunk",
   "metadata": {},
   "source": [
    "#### Programming Note:\n",
    "- I prefer to encapsulate everything within a function rather than have variables within just the notebook.\n",
    "- While I understand that this takes away from some of the perks of the sandbox environment of Jupyter Notebooks, I feel that maintaining the scope of data/variables in this way prevents issues further down the road, such as\n",
    "    - conflicting variables/variable names,\n",
    "    - unintended changes,\n",
    "    - functions confusing which data to use\n",
    "    - mutability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-remove",
   "metadata": {},
   "source": [
    "#### Data Note\n",
    "- I have chosen to undo some of the cleaning I perform in my webscraping package in order to demonstrate some common cleaning examples\n",
    "- By doing this, I can simulate likely requirements when dealing with unfamiliar/third-party data sources, such as eliminating null values and cleaning up columns/rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "patient-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_data_path() -> str:\n",
    "    return '/'.join([\n",
    "        os.getcwd().replace('src', 'data'),\n",
    "        'season-data-raw.csv'\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tender-buddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw() -> pd.DataFrame:\n",
    "    return pd.read_csv(raw_data_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-saskatchewan",
   "metadata": {},
   "source": [
    "### Get basic overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "weighted-ebony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_overview():\n",
    "    return load_raw().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-arnold",
   "metadata": {},
   "source": [
    "**Since I scraped this data myself, there should not be very many missing values, except on the rare occassion the scraper adds a blank space for a name after injuries and then fills the stats as if they were a player who DNP that game**\n",
    "</br>\n",
    "</br>\n",
    "Therefore, I know I need to drop these rows from the dataset. I will write a basic function to check if there are missing data or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_missing_data(df) -> bool:\n",
    "    return df.dropna().shape != df.shape\n",
    "    \n",
    "#     return f'{\"No missing values anywhere\" if not is_missing_values(df) else \"Data is missing some values, need to fix\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "contains_missing_data( load_raw() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-plastic",
   "metadata": {},
   "source": [
    "#### clean_data():\n",
    " - load the raw data \n",
    " - do some basic cleaning, as described by comments within chain of pandas operations\n",
    " - save as a new file 'season-data-clean.csv' to se for the rest of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_path() -> str:\n",
    "    return raw_data_path().replace('raw', 'clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data() -> None:\n",
    "    \n",
    "#     Columns must be renamed before using this\n",
    "#     Positive integers lt 255\n",
    "    uint_cols: tuple[int,...] = (\n",
    "        'home',\n",
    "        'starter',\n",
    "        'injury',\n",
    "        'w_pts',\n",
    "        'l_pts',\n",
    "        'fg',\n",
    "        'fga',\n",
    "        '3p',\n",
    "        '3pa',\n",
    "        'ft',\n",
    "        'fta',\n",
    "        'pts',\n",
    "        'ast',\n",
    "        'orb',\n",
    "        'drb',\n",
    "        'trb',\n",
    "        'stl',\n",
    "        'blk',\n",
    "        'tov',\n",
    "        'pf',\n",
    "        'ortg',\n",
    "        'drtg'\n",
    "    )\n",
    "        \n",
    "    rename_cols: dict[str,str] = {\n",
    "        'FPTS/MP': 'fppm',\n",
    "        '+/-': 'plus_minus',\n",
    "#         usage, effective field goal, and true shooting percentages dont have any similar stats, unlike field goal and field goal percentage\n",
    "#             can trim the '_perc' part off just these\n",
    "        'USG_perc': 'usg',\n",
    "        'eFG_perc': 'efg',\n",
    "        'TS_perc': 'ts',\n",
    "    }\n",
    "    \n",
    "    df: pd.DataFrame = (load_raw()\n",
    "#                         Get rid of rows containing null values\n",
    "                        .pipe( lambda df_: df_.loc[df_.isna().any(axis=1) == False] )\n",
    "#                         Rename certain columns directly so that they can be typed in df.col_name manner\n",
    "#                         and to avoid problems with subsequent step.\n",
    "                        .rename( rename_cols, axis=1 )\n",
    "#                         Convert all columns to lowercase, trim any possible blank spaces, and convert - to _\n",
    "                        .rename( columns=lambda col_name: col_name.lower().replace(' ', '').replace('-','_') )\n",
    "#                         Create new columns and correct types such that they are in optimal form\n",
    "#                             new columns: total_pts, pts_diff\n",
    "#                             uint8 --> integer column values < 255\n",
    "                        .assign(\n",
    "                            total_pts=lambda df_: df_.w_pts+df_.l_pts,\n",
    "                            # will need to correct for winners/losers\n",
    "                            pts_diff=lambda df_: df_.w_pts-df_.l_pts,\n",
    "                            **{c:lambda df_, c=c:df_[c].astype('uint8') for c in uint_cols},\n",
    "                               )\n",
    "#                         Get rid of all inactive players rows\n",
    "                        .pipe(lambda df_: df_.loc[df_['mp'] > 0.0])\n",
    "                       )\n",
    "    \n",
    "#     Correct the pts_diff column to account for if team lost by that much (cannot use conditional within assign command)\n",
    "    df.loc[df['team'] != df['w'], 'pts_diff'] *= -1\n",
    "    \n",
    "    df.to_csv(clean_data_path(), index=False)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean() -> pd.DataFrame:\n",
    "    return pd.read_csv(clean_data_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_clean().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-rates",
   "metadata": {},
   "source": [
    "#### Final check that all cleaning tasks came out as desired\n",
    "- No missing values in any rows\n",
    "- Columns all lowercase and any special formatting taken care of\n",
    "- Only specified columns for now\n",
    "- Only active players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_check() -> None:\n",
    "#     asserts for all type of cleaning want to do\n",
    "    \n",
    "    clean_df: pd.DataFrame = load_clean()\n",
    "        \n",
    "    assert(not contains_missing_data(clean_df))\n",
    "    assert(not len([char for char in ''.join(clean_df.columns) if char.isupper() or char== '-' ]))\n",
    "    assert(not len(clean_df.loc[clean_df['mp'] == 0.0]))\n",
    "    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-spending",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
